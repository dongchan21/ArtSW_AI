import os
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
import time
from openai import OpenAI # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸


# ---- 1. API í‚¤ ì„¤ì • ----
load_dotenv()

# ---- API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤. ----
openai_api_key = os.getenv("OPENAI_API_KEY")

# API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=openai_api_key)

app = FastAPI()

# CORS(Cross-Origin Resource Sharing) ì„¤ì •
origins = [
    "http://localhost:5173",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ… Role Prompting ì „ìš© ì±—ë´‡ í•¨ìˆ˜
async def generate_response(messages_from_client: list):
    """
    ì‚¬ìš©ìê°€ ë³´ë‚¸ ë©”ì‹œì§€ë¥¼ Role Prompting ì „ìš© ì±—ë´‡ìœ¼ë¡œ ì „ë‹¬í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """

    # ë©”ì‹œì§€ í¬ë§· ë³€í™˜
    gpt_messages = []
    for msg in messages_from_client:
        if msg.get("type") == "user":
            gpt_messages.append({"role": "user", "content": msg.get("text", "")})
        elif msg.get("type") == "bot":
            gpt_messages.append({"role": "assistant", "content": msg.get("text", "")})

    # âœ… Role Prompting ì „ìš© system í”„ë¡¬í”„íŠ¸
    system_prompt = {
        "role": "system",
        "content": """
ë‹¹ì‹ ì€ 'Role Prompting' ê¸°ë²•ì„ ì „ë¬¸ì ìœ¼ë¡œ ê°€ë¥´ì³ì£¼ëŠ” ì§‘ì‚¬ AIì…ë‹ˆë‹¤.

ğŸ© ì—­í• :
- Role Promptingì— ê´€í•œ ê°œë…, ì›ë¦¬, ì˜ˆì‹œ, í™œìš©ë²• ë“±ì„ ìì„¸íˆ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ë‹¤ë¥¸ í”„ë¡¬í”„íŒ… ê¸°ë²•(Few-shot, Chain-of-Thought, RAG ë“±)ì— ëŒ€í•œ ì§ˆë¬¸ì´ ì˜¤ë©´
  ê°„ë‹¨íˆ ê°œë…ë§Œ ì–¸ê¸‰í•˜ê³  ë§ˆì§€ë§‰ì— ì´ë ‡ê²Œ ë§í•´ì•¼ í•©ë‹ˆë‹¤:
  ğŸ‘‰ "ì „ Role Promptingì„ ë‹´ë‹¹í•˜ëŠ” ì§‘ì‚¬ì˜ˆìš”. ìš°ë¦¬ Role Prompting ì–˜ê¸°ë¥¼ í•´ë³¼ê¹Œìš”?"

ğŸ§  ê·œì¹™:
1ï¸âƒ£ Role Prompting ê´€ë ¨ ì§ˆë¬¸ì´ë¼ë©´, êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
2ï¸âƒ£ Few-shot, Reflection ë“± ë‹¤ë¥¸ í”„ë¡¬í”„íŒ… ê¸°ë²•ì€ ì§§ê²Œ ì •ì˜ë§Œ ì„¤ëª…í•œ ë’¤ ë°˜ë“œì‹œ ìœ„ ë©˜íŠ¸ë¥¼ ë§ë¶™ì´ì„¸ìš”.
3ï¸âƒ£ í”„ë¡¬í”„íŒ… ê¸°ë²•ê³¼ ì „í˜€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸(ì˜ˆ: ë‚ ì”¨, ìŒì‹, ì·¨ë¯¸ ë“±)ì— ëŒ€í•´ì„œëŠ”
   ë°˜ë“œì‹œ ì´ë ‡ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”:
   ğŸ‘‰ "ì£„ì†¡í•´ìš”. ì „ í”„ë¡¬í”„íŒ… ê¸°ë²•ì— ê´€í•œ ì§ˆë¬¸ë§Œ ë‹µë³€í•  ìˆ˜ ìˆì–´ìš”."
4ï¸âƒ£ ë‹µë³€ì€ í•­ìƒ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ, ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”.
5ï¸âƒ£ 'Role Prompting'ì´ë¼ëŠ” ë‹¨ì–´ëŠ” ê°•ì¡° í‘œì‹œë¡œ (ì˜ˆ: **Role Prompting**) í•´ì£¼ì„¸ìš”.
        """
    }

    full_conversation = [system_prompt] + gpt_messages

    completion = client.chat.completions.create(
        model="gpt-4o",
        messages=full_conversation,
        temperature=0.7,
    )

    gpt_response = completion.choices[0].message.content.strip()

    return {
        "success": True,
        "data": {
            "text": gpt_response
        }
    }