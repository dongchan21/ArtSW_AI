[
  {
    "id": 1,
    "key": "flour",
    "technique": "FEW SHOT 기법",
    "text": "사람에게 '문제를 풀어봐'라고 할 때, 문제만 던지면 헷갈리잖아요.\n그런데 비슷한 문제 몇 개와 그 답을 같이 보여주면 '아 이런 식으로 풀면 되는구나' 하고 감을 잡을 수 있죠. 모델도 똑같습니다.\n\n프롬프트에 작은 예시를 넣어주면, 모델이 그 패턴을 따라 새로운 답을 생성합니다.\n\n예시:\n1. **예시 없이 시키기 (zero-shot)**\n영어 문장을 한국어로 번역해줘:\nI love apples\n\n2. **few-shot으로 시키기**\n영어 → 한국어\nI like cats → 나는 고양이를 좋아해\nI go to school → 나는 학교에 간다\nI love apples → ?\n\n답: '나는 사과를 좋아한다'\n\n여기서는 예시 2개만 줬는데, 모델이 패턴을 학습해서 비슷하게 번역한 거예요.\n\n정리하자면, few-shot은 예시 몇 개를 보여주고 문제를 풀게 하는 방법이에요. 원하는 규칙을 따르게 만들고 형식을 잘 지키도록 할 수 있다는 점은 좋겠지만, 예시를 잘못 주면 모델이 그대로 따라가서 오답이 나올 수도 있겠죠."
  },
  {
    "id": 2,
    "key": "tomato",
    "technique": "역할 지정 기법",
    "text": "사람에게 '문제를 풀어봐'라고 할 때, 그냥 시키는 것보다 역할을 정해주면 훨씬 이해가 쉽습니다.\n\n예: '너는 지금 초등학교 수학 선생님이야. 초등학생에게 문제를 설명해줘.'\n\n모델도 똑같습니다. 프롬프트에서 '너는 지금 ~ 역할이야'라고 지정해주는 걸 role prompting이라고 합니다. 모델은 그 역할을 따르려고 하죠.\n\n예시:\n1. **예시 없이 시키기 (no-role)**\n'밑변 6, 높이 4인 삼각형의 넓이를 구해줘' → 답: 12\n\n2. **role prompting으로 시키기**\n'너는 초등학교 수학 선생님이야. 학생 질문에는 반드시 초등학생이 이해 가능한 수준의 풀이 과정을 설명해.'\n\n선생님: '삼각형 넓이 공식은 밑변 × 높이 ÷ 2야. 그래서 6 × 4 ÷ 2 = 12. 따라서 정답은 12란다.'\n\n정리하자면, role prompting은 모델이 특정 인격이나 역할을 맡도록 강제하는 방법이에요. 답변 스타일과 관점을 원하는 방향으로 맞출 수 있다는 점은 장점이지만, 너무 과도하게 역할을 지정하면 오히려 이상한 말투로 굳어져 버릴 수도 있겠죠."
  },
  {
    "id": 3,
    "key": "cheese",
    "technique": "마크다운 템플릿 기법",
    "text": "말을 아무렇게나 풀어놓으면 지저분해 보일 때가 많습니다. 그런데 '항목을 꼭 리스트로 써' 혹은 '표로 정리해'라고 말해주면 훨씬 읽기 편하죠. 모델도 마찬가지예요.\n\n미리 특정 템플릿을 주고 '이 형식으로 답을 채워줘'라고 하면, 모델은 그 구조를 그대로 따라 답을 만듭니다.\n\n예시:\n1. **예시 없이 시키기**\n사용자: '홍대 맛집 추천해줘. 추천 메뉴랑 가격대, 특징도 알려줘.'\n→ 답: '홍대에 맛있는 카페 있고, 강남에 고깃집도 괜찮아. 부산 회센터도 추천!' (산만함)\n\n2. **markdown_template으로 시키기**\n'아래 템플릿 형식으로 맛집 추천을 작성해줘.'\n\n### 추천 맛집\n- 위치:\n- 추천 메뉴:\n- 가격대:\n- 특징:\n\n→ 답:\n### 추천 맛집\n- 위치: 홍대\n- 추천 메뉴: 수제버거\n- 가격대: 1만~2만원\n- 특징: 분위기 좋은 감성 카페\n\n정리하자면, markdown template은 답변을 포맷팅하고 일관되게 정리하는 데 매우 유용합니다. 깔끔하고 보기 좋은 출력물을 얻을 수 있다는 점은 좋겠지만, 템플릿을 너무 과도하게 강제하면 자연스러운 표현이 줄어들 수 있다는 점은 아쉬운 부분이겠죠."
  },
  {
    "id": 4,
    "key": "pepperoni",
    "technique": "Hallucination 방지 기법",
    "text": "사람도 모를 때 '음… 아마 이럴걸?' 하고 대충 지어내는 경우가 있죠. 모델도 헷갈리면 자신 있게 틀린 말을 하는데, 이걸 hallucination이라고 합니다.\n\n예시:\n질문: '대한민국의 초대 대통령은 누구야?'\n잘못된 답변: '김구입니다.' → 사실은 이승만이 초대 대통령.\n\n정리하자면, hallucination은 모델이 실제로 존재하지 않거나 틀린 정보를 그럴듯하게 말하는 현상이에요. 모델 답변이 신뢰를 잃을 수 있다는 점은 분명 단점이지만, 프롬프트에 '모르면 모른다고 해'라든가 '출처를 반드시 제시해' 같은 조건을 달면 어느 정도 예방이 가능하다는 점은 다행이겠죠."
  },
  {
    "id": 5,
    "key": "olive",
    "technique": "RAG 기법",
    "text": "모델은 학습된 지식까지만 알기 때문에, 최신 정보나 생소한 분야의 데이터는 모를 수 있습니다. 그래서 Retrieval-Augmented Generation(RAG)을 씁니다. 즉, 검색으로 외부 정보를 가져와서 답변을 생성하는 방법이에요.\n\n예시:\n질문: '2025년 노벨 화학상 수상자는 누구야?'\n→ 모델: '잘 모르겠어요.' (틀릴 수도 있음)\n\nRAG를 쓰면:\n1. 질문을 검색기에 던져서 최신 기사나 DB 정보를 가져옴.\n2. 그 내용을 바탕으로 답변 생성.\n→ 답: '2025년 노벨 화학상은 A와 B에게 수여되었습니다.'\n\n정리하자면, RAG는 검색과 언어모델을 결합하여 답변의 정확성을 높이는 기술이에요. 최신성과 신뢰성을 확보할 수 있다는 점은 좋겠지만, 검색 품질이 낮으면 전체 성능이 크게 떨어질 수 있다는 점은 단점이겠죠."
  },
  {
    "id": 6,
    "key": "basil",
    "technique": "Reflection 기법",
    "text": "사람에게 '문제를 풀어봐'라고 할 때, 그냥 답만 쓰라고 하면 스스로 확인하기 어렵죠. 그런데 답을 낸 뒤 다시 검토하게 하면 실수를 줄일 수 있습니다.\n\n모델도 똑같습니다. 프롬프트에 답변 후 자기검토(reflection) 단계를 넣어주면, 더 나은 답을 생성합니다.\n\n예시:\n1. **Reflection 없이**\n12 × 13 = ? → 답: 144 (틀림)\n\n2. **Reflection 적용**\n문제: 12 × 13 = ?\n1단계: 답 계산 → 156\n2단계: 검토 → 12 × (10+3) = 120 + 36 = 156 → 맞음\n최종 답: 156\n\n정리하자면, reflection 기법은 모델이 답을 낸 뒤 스스로 검토하게 하는 방법이에요. 실수를 줄이고 신뢰성을 높일 수 있다는 점은 좋겠지만, 답변 과정이 길어져 속도가 느려지고 장황해질 수 있다는 점은 아쉬운 부분이겠죠."
  }
]